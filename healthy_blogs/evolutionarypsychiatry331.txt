It has been a while since I reviewed my basic premise, that homo sapiens walk around in bodies and brains exceptionally well suited for hunting and gathering in small family groups in the wilderness, and that we are not evolved for agriculture as a whole, and industrial agriculture in particular. I subscribe to the concept of Evolutionary Medicine, that diseases of civilization (I'm focused on mental health in my blog) are caused by differences between our current lives and our evolutionary suitability, and that replicating a hunter-gatherer life in many ways (as makes scientific and practical sense) can lead to better health, both physical and mental.

Here's what T. Colin Campbell, PhD and full professor (of nutritional biochemistry) at Cornell has to say about that (1): "Those who follow evolutionary history and who support the inclusion of substantial amounts of animal protein as a recommended dietary practice, make this error. Our dietary evolutionary history, while interesting, absolutely does not yield critical clues for optimal nutritional practices. Human evolution required that our ancestors make dietary choices that maximized gene proliferation."

To which I say - maximized gene proliferation means living past 30 and well into old age. Humans have grandmothers. Women are designed to live 20-30 years past menopause in order to favor a higher overall birthrate as grandmothers helped gather for their offspring's offspring and taught valuable cultural information (Textbook of Evolutionary Psychiatry: The origins of psychopathology). How could tens of thousands of generations not have selected for relative longevity and freedom from disease (both mental and physical) based on our evolutionary diets? For me it honestly makes no sense to view health data from another perspective. Bizarrely, Campbell goes on to write of how chimpanzees eat a plant-based diet (we split off from chimpanzees 5 million years ago) so the preponderance of evolution data must lean towards a plant-based (low protein) diet. So evolution (of an entirely different species) is important when it explains his theories, but not so when it doesn't.

If you watched the television series "Life," you might have seen the segment about the octopus that reproduces once then dies, leaving a zillion offspring who feast on mom's dead body, and hopefully a few make it to go on. I am not an octopus! Humans are rather on the extreme "k" side of the r versus k selection species. We have few, quality offspring and spend a lot of energy nursing them to reproductive age and beyond. Our genes want us to live for a very long time, to teach our toddling young and their toddling young how to make it in this big, bad world. What plants to eat, how to chase down a large land mammal, how to set fishing traps, where the best water holes are, how to select the "Children and Family ages 2-4 movies" on netflix and how to get the kangaroo through the alphabet maze on starfall.com (seriously, I never get to use my own computer anymore) - all of this is knowledge we are not born with, and is most efficiently learned from our elders. Though my youngest figured out how to post on facebook all on her own at 12 months. Darned intuitive apple iPhone technology!

(An aside - I definitely recommend Evolution's Captain: The Story of the Kidnapping That Led to Charles Darwin's Voyage Aboard the Beagle if you are a student of evolution. Darwin was selected to go on the voyage as a gentleman companion to the young Captain Fitzroy, who had a family and personal history of depressive mental illness, in order to offer him company and hopefully to forestall any depression on the long voyage returning some kidnapped Tierra del Fuegans back to the southernmost part of South America (no, I am not making this up). Sadly, Fitzroy, who ended up being the second governor of New Zealand and was also a devout Christian, eventually killed himself a few years after watching a debate on evolution between the Archbishop of Canterbury, Thomas Huxley, and Samuel Wilberforce.)

But what about those genetic diseases that occur after reproducing? Diseases such as Huntington's Chorea? Clearly those genes survived and are genetic, not dietary, so that evolutionary (dietary) paradigm doesn't support links to those aspects of ultimate human health. Cardiovascular disease and those other diseases of civilization (let's leave out acne and many autoimmune diseases which strike young) get us when we are old and no longer contributing to the gene pool (tell that to my 9th grade band director who died in his late 40s of an MI). Okay, decent argument, but that brings me to Iceland.

Way back in the infancy of my blog, a commenter from Iceland left me two links to some very interesting information. Turns out there is an autosomal dominant genetic disease in Iceland called Hereditary Cystatin C Amyloid Angiopathy. It is caused by a mutant protein that is deposited in the walls of small arteries, leading to brain hemorrhage and death in young adults (average age of 30). Since this is Iceland, and everyone knows everybody, the family trees of everyone with the disease were deciphered and studied. Turns out the deadly hereditary cystatin C mutation occurred in Iceland sometime around 1550, and carriers of the gene lived normal lifespans until 1830, when over the next 70 years the lifespan of those afflicted decreased from 65 to 30. "This change in life-span is an indication of a strong environmental effect on the penetrance of the mutation. The effect must have been very common as it happened in [almost] all families simultaneously in all parts of the country." In the time from 1830 to 1900, Iceland changed from a traditional cow and milk based diets to a more "Western" diet similar to Europeans. In one remote region of Iceland, the lifespan shortening occurred 20 years later than in the other related family groups - that was one of the later regions to adopt the Western diet. So here we have an example of how an autosomal dominant genetic disease seems to be affected by diet.

Which brings me back to Huntington's Chorea. In my last post, I mentioned a study that showed that carriers of the mutant huntingtin gene (an autosomal dominant gene with complete penetrance, meaning everyone with the gene gets a progressive, deadly neurological illness with no cure but steady and inevitable degeneration leading to death over 20 years that begins between the ages of 20 and 44, thereabouts) had a much higher rate of positive test for anti-gliadin (wheat protein) antibodies than the general population. The huntingtin gene probably codes for a type of microtubule or vesicle protein, basically structural proteins that anchor the mitochondria in nerve cells. The mutant, deadly gene has extra trinucleotide repeats of CAG, coding for an unstable version of the huntingtin protein. A normal gene will have less than 20 CAGs in a row. A mutant gene 36 or more. The more trinucleotide repeats, the earlier the disease seems to strike. What does this have to do with wheat?

Here's the really weird part. That CAG DNA code repeat I was talking about? CAG is the genetic code for the amino acid glutamine. The mutant extra repeats is called a "polyglutamine repeat", and there are a number of genetic diseases that are also caused by this polyglutamine repeat. Turns out that polyglutamine tracts are also present in gliadin - the wheat protein. A possible explanation is that the body recognized the abnormal polyglutamine tracts made in the cells with the abnormal gene, and the wheat proteins looked a lot like the abnormal protein so that the people with Huntington's mounted an immune response to the wheat proteins. But wheat protein exposure has also been associated with non-Huntington's ataxias. Could wheat gliadin polyglutamine exposure itself and an abnormal autoimmune response lead to the protein aggregation in Huntington's disease? In other words, does our ubiquitous exposure to dietary wheat protein modify the natural history of Huntington's disease? Somewhat like Western dietary exposure seems to modify the natural history of Hereditary Cystatin C Amyloid Angiopathy?

No one knows.

But an evolutionary perspective would lead one to pursue those questions.

For decades, the U.S. government has been freewheeling with sugar and heart disease, repeating the fact that there was no data to suggest sugar had anything to do with it. Well, here's an abstract from a study in JAMA in April of 2010, showing a strong correlation between dietary sweetener consumption and a bad cholesterol profile (low HDL and high triglycerides). The money quote from the abstract? "No known studies have examined the association between the consumption of added sugars and lipid measures."

That's right. No one bothered to publish a study on sugar and blood lipid profiles until 2010.
The jury on wheat is still out. In the mean time, I'll fall back to the safe evolutionary medicine position, and avoid it.