Remember Richard Eastell? To summarize briefly, he is a professor at Sheffield University who was lead author on a publication that showed positive results for the osteoporosis drug Actonel. One problem: the data did not actually provide good news for Actonel. In a key graph in the published paper, 40% of patient data was missing. Now that's an interesting form of science: Just eliminate the pesky 40% of the data that don't go along with your hypothesis and POOF!, you get exactly the results you are looking for. An excellent writeup of the situation can be seen in Jennifer Washburn's excellent piece in Slate. Making the plot more interesting, Eastell did not have the raw data; Procter & Gamble's (Actonel's sponsor) statisticians were in charge of the analysis. Hence the missing 40% of the data, which helped to cast Actonel in a more positive light. Read more on the topic here. When all data are included, the analysis does not support Actonel's marketing points. Eastell signed off on the original (misleading) paper saying that he had seen all of the data, which was, of course not true.

I noted in October 2006 that Eastell was chairing a session on osteoporosis, one that charged a hefty registration fee. The website promoting the session at the time mentioned: "This course is suitable for pharmaceutical industry personnel from clinical through to marketing disciplines." I suppose that Eastell is a key opinion leader in his field. Being willing to put one's name on a paper where the key graph knocks out 40% of the data is a good step toward becoming an influential academic these days. I suppose Eastell could at least claim ignorance, since he was unfamiliar with the underlying data.

In psychiatry, Charles Nemeroff, a key opinion leader, put his name on a continuing medical education presentation in which the data don't match with the published article that was based on the same data set. In the CME presentation, the medication (risperidone) outperformed placebo, although the published report indicated that risperidone did not beat a placebo, and in the CME presentation, risperidone was claimed to improve sexual functioning, which was never mentioned in the published article.

Eastell and a colleague recently received a roughly $7.5 million grant. Good for them. I've got nothing against the guy personally; I just find it
interesting that he is getting rewarded nicely despite the whole Actonel fiasco. And I've only described a wee bit of that strange saga. The Scientific Misconduct Blog has much, much more. Like the part where he told Blumsohn to stop bothering Procter & Gamble about the data because P & G was a good source of income for the university. I've got no problem with excellence being rewarded. Perhaps Eastell has done many excellent things. However, during the P &G/Actonel fiasco, Eastell was willing to let the sponsors push him around, even if science was being bastardized in the process. Their money meant more than good science. And if patients took Actonel thinking that it was more effective than it actually was, who cares -- they're not the ones providing the research funding, right?

Think about this for a second. Many people have been up in arms about the recently unveiled Vioxx ghostwriting scandal. For a fantastic take on the scandal, see Health Care Renewal or Hooked. Briefly, Merck and its associated medical writers wrote manuscripts that said nice things about Vioxx. Then academic authors/key opinion leaders were found to review the papers and stick their names on as lead authors. Mind you, "reviewing" the papers often meant simply meant making minimal edits, if even putting in that much effort. Did they see the data? They saw tables and figures provided by Merck, but did they see the raw data? In most cases, apparently not. Doesn't that make them information launderers? They take industry data, and clean it up with their academic reputation. Oh, Dr. So-and-So is at Sheffield or Emory or Harvard... -- he must have made sure that the sponsoring drug company is portraying the data accurately. A veneer of credibility. And an extra publication for the key opinion leader, which makes the KOL that much more important in the academic world where publication envy runs rampant.

This system is not exactly set up to benefit patient outcomes, is it?