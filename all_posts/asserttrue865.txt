in an interesting post at the websphere community blog , andrew spyker explains why it is that when you switch from bit java to a bit runtime environment , you typically see speed go down percent and memory consumption go up by around percent the latter is explained by the fact that addresses are simply bigger in bit land , and complex data structures use a lot of bit values even if they only need bit values the reason performance drops is because although address width has gotten bigger , processor memory caches have not got bigger in terms of overall kbytes available thus , you are bound to see things drop out of l and l cache more often hence cache misses go up and speed goes down why , then , would anyone invest in bit machines if the bit jvm is going to give you an immediate performance hit ? the answer is simple the main reason you go with bit architecture is to address a larger memory space and flow more bytes through the data bus in other word , if you 're running heap intensive apps , you have a lot to gain by going bit if you have an app that needs more than around gb of ram , you have no choice why gb ? it might actually be less than that on a gb win machine , the os hogs gb of ram and will only let applications have gb the jvm , of course , needs its own ram and then there 's the heap space within the jvm that 's what your app uses it turns out that the jvm heap has to be contiguous for reasons related to garbage collection the largest piece of contiguous heap you can get , after the jvm loads and taking into account all the garbage that has to run in the background in order to make windows work , is between gb and gb roughly depending on the circumstances to get more heap than that means either moving to a bit jvm or using terracotta the latter if you have n't heard of it is a shared memory jvm clustering technology that essentially gives you unlimited heap space or should i say , heap space is limited only by the amount of disk space terracotta pages out to disk as necessary a good explanation of how that works is given here but getting back to the bit memory consumption issue this issue of ram requirements for ordinary java apps increasing dramatically when you run them on a bit machine is a huge problem , potentially , for hosting services that run many instances of java apps for saas customers , because it means your scale out costs rise much faster than they should but it turns out there are things you can do ibm , in its jvm , uses a clever pointer compression scheme to in essence make good use of unused high order bits in a bit machine the result ? performance is within percent of bit and ram growth is only percent graphs here oracle has a similar trick for bea 's jrockit jvm , and sun is just now testing a new feature called compressed oops ordinary object pointers the latter is supposedly included in a special jdk performance release survey required you have to use special command line options to get the new features to work , however anyway , now you know why bit java can be slow and piggish everything 's fatter in bit land for information about large memory support in windows , see this article at support microsoft com also consult this post at sinewalker